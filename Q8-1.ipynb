{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 首先，落俗套地讓我們引入該用到的東西們，並且很勇敢的說出自己是複製貼上來的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=tensorflow\n"
     ]
    }
   ],
   "source": [
    "%env KERAS_BACKEND=tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from ipywidgets import interact, IntSlider, Button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Keras functions\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Keras dataset\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# Keras utils\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 接著，我也不知道有甚麼資料好用的，就用minst吧^.^，順便把資料調整好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 18s 2us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train0, y_train0), (x_test0, y_test0) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"There are %d training data with size %d x %d\" %x_train0.shape)\n",
    "#print(\"There are %d testing  data with size %d x %d\" %x_test0.shape)\n",
    "\n",
    "x_train = x_train0.reshape(60000, 28*28)\n",
    "x_test = x_test0.reshape(10000, 28*28)\n",
    "\n",
    "x_train -= x_train.min()\n",
    "x_train = x_train/x_train.max()\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train0, 10)\n",
    "y_test = np_utils.to_categorical(y_test0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "東西都設定好了，就讓我們來玩玩可愛的(?)function API吧! <br>\n",
    "首先要決定好我們的神經網路該長甚麼樣子，總之就隨便畫畫吧XD\n",
    "\n",
    "![my NN](https://i.imgur.com/7wlfaaE.png)\n",
    "\n",
    "順便把函數名字跟每層的變數都取好名字了，至於每個地方的activation function...隨便啦，先都用sigmoid，有分支的就上面用relu，最後再用softmax吧<br>\n",
    "之所以會想這樣拉，主要是想試試看把不同分支的部分牽在一起會怎麼樣(就是不想畫成圖論的tree就對了拉)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import concatenate, add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_1 = Dense(500, activation='sigmoid')\n",
    "f_2 = Dense(300, activation='relu')\n",
    "f_3 = Dense(300, activation='sigmoid')\n",
    "f_4 = Dense(150, activation='relu')\n",
    "f_5 = Dense(100, activation='sigmoid')\n",
    "f_6 = Dense(350, activation='softmax')\n",
    "f_7 = Dense(10, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\X555LN\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "x = Input(shape=(784,))\n",
    "\n",
    "h_1 = f_1(x)\n",
    "h_21 = f_2(h_1)\n",
    "h_22 = f_3(h_1)\n",
    "h_31 = f_4(h_21)\n",
    "h_32 = f_5(h_21)\n",
    "\n",
    "u_1 = concatenate([h_32, h_22])\n",
    "h_4 = f_6(u_1)\n",
    "\n",
    "u_2 = concatenate([h_31, h_4])\n",
    "y = f_7(u_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_2:0\", shape=(?, 784), dtype=float32)\n",
      "Tensor(\"dense_1/Sigmoid:0\", shape=(?, 500), dtype=float32)\n",
      "Tensor(\"dense_2/Relu:0\", shape=(?, 300), dtype=float32)\n",
      "Tensor(\"dense_3/Sigmoid:0\", shape=(?, 300), dtype=float32)\n",
      "Tensor(\"dense_4/Relu:0\", shape=(?, 150), dtype=float32)\n",
      "Tensor(\"dense_5/Sigmoid:0\", shape=(?, 100), dtype=float32)\n",
      "Tensor(\"dense_6/Softmax:0\", shape=(?, 350), dtype=float32)\n",
      "Tensor(\"dense_7/Softmax:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#print(x)\n",
    "#print(h_1)\n",
    "#print(h_21)\n",
    "#print(h_22)\n",
    "#print(h_31)\n",
    "#print(h_32)\n",
    "#print(h_4)\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大功告成，可以睡...欸不是，建model然後compile啦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 784)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 500)          392500      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 300)          150300      dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 100)          30100       dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 300)          150300      dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 400)          0           dense_5[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 150)          45150       dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 350)          140350      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 500)          0           dense_4[0][0]                    \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 10)           5010        concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 913,710\n",
      "Trainable params: 913,710\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(x, y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mse', optimizer = SGD(lr=0.03), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.0842 - acc: 0.2926\n",
      "Epoch 2/25\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.0836 - acc: 0.2959\n",
      "Epoch 3/25\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.0829 - acc: 0.2982\n",
      "Epoch 4/25\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.0821 - acc: 0.3037\n",
      "Epoch 5/25\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0812 - acc: 0.3148\n",
      "Epoch 6/25\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.0802 - acc: 0.3253\n",
      "Epoch 7/25\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0791 - acc: 0.3386\n",
      "Epoch 8/25\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.0780 - acc: 0.3550\n",
      "Epoch 9/25\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.0769 - acc: 0.3717\n",
      "Epoch 10/25\n",
      "60000/60000 [==============================] - 7s 125us/step - loss: 0.0757 - acc: 0.3945\n",
      "Epoch 11/25\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 0.0745 - acc: 0.4095\n",
      "Epoch 12/25\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.0733 - acc: 0.4266\n",
      "Epoch 13/25\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 0.0722 - acc: 0.4442\n",
      "Epoch 14/25\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0710 - acc: 0.4586\n",
      "Epoch 15/25\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.0698 - acc: 0.4734\n",
      "Epoch 16/25\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.0687 - acc: 0.4832\n",
      "Epoch 17/25\n",
      "60000/60000 [==============================] - 8s 142us/step - loss: 0.0675 - acc: 0.4932\n",
      "Epoch 18/25\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.0663 - acc: 0.5071\n",
      "Epoch 19/25\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.0650 - acc: 0.5164\n",
      "Epoch 20/25\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.0637 - acc: 0.5287\n",
      "Epoch 21/25\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.0624 - acc: 0.5404\n",
      "Epoch 22/25\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.0611 - acc: 0.5529\n",
      "Epoch 23/25\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.0598 - acc: 0.5648\n",
      "Epoch 24/25\n",
      "60000/60000 [==============================] - 8s 125us/step - loss: 0.0584 - acc: 0.5799\n",
      "Epoch 25/25\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.0571 - acc: 0.5913 2s - loss: 0.0 - ETA: 1s - loss: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xcc9215ec50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size = 300, epochs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 113us/step\n",
      "Loss: 0.059601\n",
      "準確率: 53.830000\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)\n",
    "print(\"Loss: %f\" %score[0])\n",
    "print(\"準確率: %f\" %(score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 哼...準確率雖然有1.8個教授，但說到底也只是54%，機器學習的世界真是奧妙呢....\n",
    "不過說起來，感覺準確率還能再提升呢，讓他多做個幾倍看看吧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0558 - acc: 0.6065\n",
      "Epoch 2/70\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.0545 - acc: 0.6226\n",
      "Epoch 3/70\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0532 - acc: 0.6335\n",
      "Epoch 4/70\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.0519 - acc: 0.6477\n",
      "Epoch 5/70\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.0507 - acc: 0.6638\n",
      "Epoch 6/70\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.0495 - acc: 0.6784\n",
      "Epoch 7/70\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0483 - acc: 0.6940\n",
      "Epoch 8/70\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0471 - acc: 0.7107\n",
      "Epoch 9/70\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0459 - acc: 0.7231\n",
      "Epoch 10/70\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.0448 - acc: 0.7366\n",
      "Epoch 11/70\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.0437 - acc: 0.7494 1s - loss\n",
      "Epoch 12/70\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.0425 - acc: 0.7624\n",
      "Epoch 13/70\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0415 - acc: 0.7716\n",
      "Epoch 14/70\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.0404 - acc: 0.7819\n",
      "Epoch 15/70\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0394 - acc: 0.7897\n",
      "Epoch 16/70\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0383 - acc: 0.7970\n",
      "Epoch 17/70\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0374 - acc: 0.8035\n",
      "Epoch 18/70\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0364 - acc: 0.8092\n",
      "Epoch 19/70\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0355 - acc: 0.8142\n",
      "Epoch 20/70\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.0346 - acc: 0.8179\n",
      "Epoch 21/70\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.0338 - acc: 0.8221\n",
      "Epoch 22/70\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0330 - acc: 0.8251\n",
      "Epoch 23/70\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.0322 - acc: 0.8281\n",
      "Epoch 24/70\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 0.0315 - acc: 0.8312\n",
      "Epoch 25/70\n",
      "60000/60000 [==============================] - 8s 133us/step - loss: 0.0308 - acc: 0.8339\n",
      "Epoch 26/70\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.0301 - acc: 0.8362\n",
      "Epoch 27/70\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.0295 - acc: 0.8390\n",
      "Epoch 28/70\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.0289 - acc: 0.8407\n",
      "Epoch 29/70\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.0284 - acc: 0.8433\n",
      "Epoch 30/70\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.0278 - acc: 0.8450\n",
      "Epoch 31/70\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0273 - acc: 0.8465\n",
      "Epoch 32/70\n",
      "60000/60000 [==============================] - 15s 249us/step - loss: 0.0269 - acc: 0.8482\n",
      "Epoch 33/70\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.0264 - acc: 0.8501\n",
      "Epoch 34/70\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.0260 - acc: 0.8517\n",
      "Epoch 35/70\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.0256 - acc: 0.8534\n",
      "Epoch 36/70\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.0252 - acc: 0.8541\n",
      "Epoch 37/70\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.0249 - acc: 0.8556\n",
      "Epoch 38/70\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0245 - acc: 0.8572\n",
      "Epoch 39/70\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.0242 - acc: 0.8587\n",
      "Epoch 40/70\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.0239 - acc: 0.8603\n",
      "Epoch 41/70\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.0236 - acc: 0.8611\n",
      "Epoch 42/70\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.0233 - acc: 0.8627\n",
      "Epoch 43/70\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 0.0230 - acc: 0.8639\n",
      "Epoch 44/70\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.0228 - acc: 0.8651\n",
      "Epoch 45/70\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0225 - acc: 0.8666\n",
      "Epoch 46/70\n",
      "60000/60000 [==============================] - 11s 183us/step - loss: 0.0223 - acc: 0.8671\n",
      "Epoch 47/70\n",
      "60000/60000 [==============================] - 9s 144us/step - loss: 0.0221 - acc: 0.8683\n",
      "Epoch 48/70\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.0218 - acc: 0.8692\n",
      "Epoch 49/70\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 0.0216 - acc: 0.8699\n",
      "Epoch 50/70\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.0214 - acc: 0.8712\n",
      "Epoch 51/70\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0212 - acc: 0.8721\n",
      "Epoch 52/70\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.0210 - acc: 0.8731\n",
      "Epoch 53/70\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.0209 - acc: 0.8733\n",
      "Epoch 54/70\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.0207 - acc: 0.8745\n",
      "Epoch 55/70\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0205 - acc: 0.8748\n",
      "Epoch 56/70\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0204 - acc: 0.8760\n",
      "Epoch 57/70\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.0202 - acc: 0.8758\n",
      "Epoch 58/70\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 0.0201 - acc: 0.8773\n",
      "Epoch 59/70\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.0199 - acc: 0.8778\n",
      "Epoch 60/70\n",
      "60000/60000 [==============================] - 11s 187us/step - loss: 0.0198 - acc: 0.8782\n",
      "Epoch 61/70\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0196 - acc: 0.8790\n",
      "Epoch 62/70\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0195 - acc: 0.8795\n",
      "Epoch 63/70\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.0194 - acc: 0.8802\n",
      "Epoch 64/70\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.0193 - acc: 0.8812\n",
      "Epoch 65/70\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.0191 - acc: 0.8811 1s - loss: 0.\n",
      "Epoch 66/70\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.0190 - acc: 0.8822\n",
      "Epoch 67/70\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.0189 - acc: 0.8826\n",
      "Epoch 68/70\n",
      "60000/60000 [==============================] - 8s 125us/step - loss: 0.0188 - acc: 0.8832\n",
      "Epoch 69/70\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.0187 - acc: 0.8834\n",
      "Epoch 70/70\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 0.0186 - acc: 0.8843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xccacd4fc50>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size = 300, epochs = 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 116us/step\n",
      "Loss: 0.025542\n",
      "準確率: 83.860000\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)\n",
    "print(\"Loss: %f\" %score[0])\n",
    "print(\"準確率: %f\" %(score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 喔喔喔提升到了84%，將近三個教授呢! 果然是我太沒耐心了。\n",
    "不過看起來稍微弄亂網路並沒有很有效的提升，人生真難呢..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
